general:
  debug: true
  instance_name: "Prime Search"
  privacypolicy_url: false
  contact_url: false
  enable_metrics: true

search:
  safe_search: 0
  autocomplete: ""
  autocomplete_min: 4
  default_lang: "en"
  ban_time_on_fail: 5
  max_ban_time_on_fail: 120
  suspended_times:
    SearxEngineAccessDenied: 0
    SearxEngineCaptcha: 0
    SearxEngineTooManyRequests: 0
    cf_SearxEngineCaptcha: 0
    cf_SearxEngineAccessDenied: 0
    recaptcha_SearxEngineCaptcha: 0

  formats:
    - html
    - json
    - csv

server:
  # If you change port, bind_address or base_url don't forget to rebuild
  # instance's environment (make buildenv). Is overwritten by ${SEARXNG_PORT}
  # and ${SEARXNG_BIND_ADDRESS}
  port: 8888
  bind_address: "127.0.0.1"
  # public URL of the instance, to ensure correct inbound links. Is overwritten
  # by ${SEARXNG_URL}.
  base_url: false  # "http://example.com/location"
  limiter: false  # rate limit the number of request on the instance, block some bots

  # If your instance owns a /etc/searxng/settings.yml file, then set the following
  # values there.

  secret_key: "d0cb07a1775b66cb5053649594679f5d521e8f0d78e3a9288e60fa9c587766bb"  # Is overwritten by ${SEARXNG_SECRET}
  # Proxying image results through searx
  image_proxy: true
  # 1.0 and 1.1 are supported
  http_protocol_version: "1.0"
  #############################################################################
  #############################################################################
  #############################################################################
  # POST queries are more secure as they don't show up in history but may cause
  # problems when using Firefox containers
  #############################################################################
  #############################################################################
  #############################################################################
  method: "GET"
  default_http_headers:
    X-Content-Type-Options: nosniff
    X-XSS-Protection: 1; mode=block
    X-Download-Options: noopen
    X-Robots-Tag: noindex, nofollow
    Referrer-Policy: no-referrer

redis:
  # URL to connect redis database. Is overwritten by ${SEARXNG_REDIS_URL}.
  # https://redis-py.readthedocs.io/en/stable/connections.html#redis.client.Redis.from_url
  url: false

ui:
  # Custom static path - leave it blank if you didn't change
  static_path: ""
  static_use_hash: false
  # Custom templates path - leave it blank if you didn't change
  templates_path: ""
  # query_in_title: When true, the result page's titles contains the query
  # it decreases the privacy, since the browser can records the page titles.
  query_in_title: false
  # infinite_scroll: When true, automatically loads the next page when scrolling to bottom of the current page.
  infinite_scroll: true
  # ui theme
  default_theme: simple
  # center the results ?
  center_alignment: false
  # URL prefix of the internet archive, don't forgett trailing slash (if needed).
  # cache_url: "https://webcache.googleusercontent.com/search?q=cache:"
  # Default interface locale - leave blank to detect from browser information or
  # use codes from the 'locales' config section
  default_locale: ""
  # Open result links in a new tab by default
  # results_on_new_tab: false
  theme_args:
    # style of simple theme: auto, light, dark
    simple_style: dark

# Lock arbitrary settings on the preferences page.  To find the ID of the user
# setting you want to lock, check the ID of the form on the page "preferences".
#
# preferences:
#   lock:
#     - language
#     - autocomplete
#     - method
#     - query_in_title

# searx supports result proxification using an external service:
# https://github.com/asciimoo/morty uncomment below section if you have running
# morty proxy the key is base64 encoded (keep the !!binary notation)
# Note: since commit af77ec3, morty accepts a base64 encoded key.
#
# result_proxy:
#   url: http://127.0.0.1:3000/
#   # the key is a base64 encoded string, the YAML !!binary prefix is optional
#   key: !!binary "your_morty_proxy_key"
#   # [true|false] enable the "proxy" button next to each result
#   proxify_results: true

# communication with search engines
#
outgoing:
  # default timeout in seconds, can be override by engine
  request_timeout: 300.0 # 5 minutes timeout
  # the maximum timeout in seconds
  # max_request_timeout: 10.0
  # suffix of searx_useragent, could contain information like an email address
  # to the administrator
  useragent_suffix: ""
  # The maximum number of concurrent connections that may be established.
  pool_connections: 100
  # Allow the connection pool to maintain keep-alive connections below this
  # point.
  pool_maxsize: 20
  # See https://www.python-httpx.org/http2/
  enable_http2: true
  # uncomment below section if you want to use a custom server certificate
  # see https://www.python-httpx.org/advanced/#changing-the-verification-defaults
  # and https://www.python-httpx.org/compatibility/#ssl-configuration
  #  verify: ~/.mitmproxy/mitmproxy-ca-cert.cer
  #
  # uncomment below section if you want to use a proxyq see: SOCKS proxies
  #   https://2.python-requests.org/en/latest/user/advanced/#proxies
  # are also supported: see
  #   https://2.python-requests.org/en/latest/user/advanced/#socks
  #
  # proxies:
  #   all://:
  #     - http://nwsjzvph:3ibpkcf5tu0s@2.56.119.93:5074
  #     - http://nwsjzvph:3ibpkcf5tu0s@185.199.229.156:7492
  #     - http://nwsjzvph:3ibpkcf5tu0s@185.199.228.220:7300
  #     - http://nwsjzvph:3ibpkcf5tu0s@185.199.231.45:8382
  #     - http://nwsjzvph:3ibpkcf5tu0s@188.74.210.207:6286
  #     - http://nwsjzvph:3ibpkcf5tu0s@188.74.183.10:8279
  #     - http://nwsjzvph:3ibpkcf5tu0s@45.155.68.129:8133
  #     - http://nwsjzvph:3ibpkcf5tu0s@154.95.36.199:6893
  #     - http://nwsjzvph:3ibpkcf5tu0s@45.94.47.66:8110
  #
  #  using_tor_proxy: true
  #
  # Extra seconds to add in order to account for the time taken by the proxy
  #
  #  extra_proxy_timeout: 10.0
  #
  # uncomment below section only if you have more than one network interface
  # which can be the source of outgoing search requests
  #
  #  source_ips:
  #    - 1.1.1.1
  #    - 1.1.1.2
  #    - fe80::/126

# External plugin configuration, for more details see
#   https://docs.searxng.org/dev/plugins.html
#
# plugins:
#   - plugin1
#   - plugin2
#   - ...

# Comment or un-comment plugin to activate / deactivate by default.
#
# enabled_plugins:
#   # these plugins are enabled if nothing is configured ..
#   - 'Hash plugin'
#   - 'Search on category select'
#   - 'Self Information'
#   - 'Tracker URL remover'
#   - 'Ahmia blacklist'  # activation depends on outgoing.using_tor_proxy
#   # these plugins are disabled if nothing is configured ..
#   - 'Hostname replace'  # see hostname_replace configuration below
#   - 'Open Access DOI rewrite'
#   - 'Vim-like hotkeys'
#   - 'Tor check plugin'
#   # Read the docs before activate: auto-detection of the language could be
#   # detrimental to users expectations / users can activate the plugin in the
#   # preferences if they want.
#   - 'Autodetect search language'

# Configuration of the "Hostname replace" plugin:
#
# hostname_replace:
#   '(.*\.)?youtube\.com$': 'invidious.example.com'
#   '(.*\.)?youtu\.be$': 'invidious.example.com'
#   '(.*\.)?youtube-noocookie\.com$': 'yotter.example.com'
#   '(.*\.)?reddit\.com$': 'teddit.example.com'
#   '(.*\.)?redd\.it$': 'teddit.example.com'
#   '(www\.)?twitter\.com$': 'nitter.example.com'
#   # to remove matching host names from result list, set value to false
#   'spam\.example\.com': false

checker:
  # disable checker when in debug mode
  off_when_debug: true

  # use "scheduling: false" to disable scheduling
  # scheduling: interval or int

  # to activate the scheduler:
  # * uncomment "scheduling" section
  # * add "cache2 = name=searxngcache,items=2000,blocks=2000,blocksize=4096,bitmap=1"
  #   to your uwsgi.ini

  # scheduling:
  #   start_after: [300, 1800]  # delay to start the first run of the checker
  #   every: [86400, 90000]     # how often the checker runs

  # additional tests: only for the YAML anchors (see the engines section)
  #
  additional_tests:
    rosebud: &test_rosebud
      matrix:
        query: rosebud
        lang: en
      result_container:
        - not_empty
        - ['one_title_contains', 'citizen kane']
      test:
        - unique_results

    android: &test_android
      matrix:
        query: ['android']
        lang: ['en', 'de', 'fr', 'zh-CN']
      result_container:
        - not_empty
        - ['one_title_contains', 'google']
      test:
        - unique_results

  # tests: only for the YAML anchors (see the engines section)
  tests:
    infobox: &tests_infobox
      infobox:
        matrix:
          query: ["linux", "new york", "bbc"]
        result_container:
          - has_infobox

categories_as_tabs:
  general:
  images:
  videos:
  news:
  map:
  music:
  it:
  science:
  files:
  social media:

engines:
  - name: bing
    engine: bing
    shortcut: bi
    title_query: title
    content_query: description

  - name: duckduckgo
    engine: duckduckgo
    shortcut: ddg
    title_query: title
    content_query: description

  - name: google
    engine: google
    shortcut: go
    title_query: title
    content_query: description

  - name: yahoo
    engine: yahoo
    title_query: title
    content_query: description
    
doi_resolvers:
  oadoi.org: 'https://oadoi.org/'
  doi.org: 'https://doi.org/'
  doai.io: 'https://dissem.in/'
  sci-hub.se: 'https://sci-hub.se/'
  sci-hub.st: 'https://sci-hub.st/'
  sci-hub.ru: 'https://sci-hub.ru/'

default_doi_resolver: 'oadoi.org'